{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75e70036-78ae-4fb2-bfa5-718ff2068d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa288c14-5a8b-4177-8ad6-b774596423af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) __testing_word2vec-matrix-synopsis (-1 records):\n",
      "\t [THIS IS ONLY FOR TESTING] Word vecrors  + .....\n",
      "\n",
      "2) conceptnet-numberbatch-17-06-300 (1917247 records):\n",
      "\t ConceptNet Numberbatch consists of state + .....\n",
      "\n",
      "3) fasttext-wiki-news-subwords-300 (999999 records):\n",
      "\t 1 million word vectors trained on Wikipe + .....\n",
      "\n",
      "4) glove-twitter-100 (1193514 records):\n",
      "\t Pre-trained vectors based on  2B tweets, + .....\n",
      "\n",
      "5) glove-twitter-200 (1193514 records):\n",
      "\t Pre-trained vectors based on 2B tweets,  + .....\n",
      "\n",
      "6) glove-twitter-25 (1193514 records):\n",
      "\t Pre-trained vectors based on 2B tweets,  + .....\n",
      "\n",
      "7) glove-twitter-50 (1193514 records):\n",
      "\t Pre-trained vectors based on 2B tweets,  + .....\n",
      "\n",
      "8) glove-wiki-gigaword-100 (400000 records):\n",
      "\t Pre-trained vectors based on Wikipedia 2 + .....\n",
      "\n",
      "9) glove-wiki-gigaword-200 (400000 records):\n",
      "\t Pre-trained vectors based on Wikipedia 2 + .....\n",
      "\n",
      "10) glove-wiki-gigaword-300 (400000 records):\n",
      "\t Pre-trained vectors based on Wikipedia 2 + .....\n",
      "\n",
      "11) glove-wiki-gigaword-50 (400000 records):\n",
      "\t Pre-trained vectors based on Wikipedia 2 + .....\n",
      "\n",
      "12) word2vec-google-news-300 (3000000 records):\n",
      "\t Pre-trained vectors trained on a part of + .....\n",
      "\n",
      "13) word2vec-ruscorpora-300 (184973 records):\n",
      "\t Word2vec Continuous Skipgram vectors tra + .....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info = api.info()\n",
    "i=1\n",
    "for model_name, model_data in sorted(info['models'].items()):\n",
    "    print(f\"{i}) {model_name} ({model_data.get('num_records',-1)} records):\\n\\t {model_data['description'][:40]} + .....\\n\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8719353-160a-457e-b4d2-7d5aef8f55f9",
   "metadata": {},
   "source": [
    "- [Word2Vec](#w2v)\n",
    "- [Glove](#glove)\n",
    "- [FastText](#ftext)\n",
    "- [ELMO](#elmo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e58d00-dcec-4cc6-ab7c-cd45e13b810e",
   "metadata": {},
   "source": [
    "<a id=\"w2v\"></a>\n",
    "___\n",
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea01841a-5586-407a-87dc-a9c63d8d864a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1764792-14ab-44ce-8a60-ff47136f0047",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar(\"tea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "381ceebb-d894-437c-a5f7-b060929ab36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Tea', 0.7009038329124451),\n",
       " ('teas', 0.6727380156517029),\n",
       " ('shape_Angius', 0.6323482990264893),\n",
       " ('activist_Jamie_Radtke', 0.5863860249519348),\n",
       " ('decaffeinated_brew', 0.5839536190032959),\n",
       " ('planter_bungalow', 0.575829029083252),\n",
       " ('herbal_tea', 0.5731174349784851),\n",
       " ('coffee', 0.5635291934013367),\n",
       " ('jasmine_tea', 0.548339307308197),\n",
       " ('Tea_NASDAQ_PEET', 0.5402544140815735)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(\"tea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79d1d7a3-da8f-4fa0-95b3-9f1caf35ce5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('heroin_ecstasy_LSD', 0.6842464804649353),\n",
       " ('coking', 0.5356490612030029),\n",
       " ('metallurgical_coke', 0.5258563160896301),\n",
       " ('cocain', 0.5173832178115845),\n",
       " ('caustic_soda', 0.510305643081665),\n",
       " ('herion', 0.5091201066970825),\n",
       " ('Refiner_Sunoco', 0.5074807405471802),\n",
       " ('cocaine', 0.49948909878730774),\n",
       " ('heroin', 0.49005699157714844),\n",
       " ('crystal_methamphetamines', 0.4898897409439087)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(\"coke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "abffe51e-cc7e-40e7-8d1d-6d491f4dc8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contextually Close Words: ('tea','coffee') = 0.436\n",
      "Syntactically Close Words:   ('tea','pea') = 0.706\n",
      "More Examples:           ('black','coffee') = 0.895\n",
      "More Examples:           ('white','orange') = 0.497\n"
     ]
    }
   ],
   "source": [
    "print(f\"Contextually Close Words: ('tea','coffee') = {round(wv.distance('tea','coffee'),3)}\")\n",
    "print(f\"Syntactically Close Words:   ('tea','pea') = {round(wv.distance('tea','pea'),3)}\")\n",
    "print(f\"More Examples:           ('black','coffee') = {round(wv.distance('black','coffee'),3)}\")\n",
    "print(f\"More Examples:           ('white','orange') = {round(wv.distance('white','orange'),3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c1e396-04e0-4851-b827-44cdced11e05",
   "metadata": {},
   "source": [
    "<a id=\"glove\"></a>\n",
    "___\n",
    "# Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83fcda01-d170-472e-97e6-290d414b4ca1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========================-------------------------] 51.5% 102.8/199.5MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================-----------------] 66.2% 132.2/199.5MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========================================-------] 87.1% 173.7/199.5MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 199.5/199.5MB downloaded\n"
     ]
    }
   ],
   "source": [
    "glove = api.load('glove-twitter-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a85b74e-bc67-4b37-b4fe-e4d9ac9c0b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('coffee', 0.8929039239883423),\n",
       " ('milk', 0.8667818903923035),\n",
       " ('wine', 0.8507667183876038),\n",
       " ('cream', 0.8502466678619385),\n",
       " ('ice', 0.8362607955932617),\n",
       " ('juice', 0.8177549242973328),\n",
       " ('beer', 0.8157103657722473),\n",
       " ('sugar', 0.8099127411842346),\n",
       " ('cake', 0.8080540895462036),\n",
       " ('drink', 0.8000376224517822)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.most_similar(\"tea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bf0dbe2-936d-4b1f-9b9e-6e8a4c6dee02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('soda', 0.8957321643829346),\n",
       " ('juice', 0.8915079236030579),\n",
       " ('milk', 0.8666771054267883),\n",
       " ('sprite', 0.8605549335479736),\n",
       " ('drink', 0.8440005779266357),\n",
       " ('bottle', 0.8422785997390747),\n",
       " ('syrup', 0.821537435054779),\n",
       " ('lemonade', 0.8137418627738953),\n",
       " ('grape', 0.8041874170303345),\n",
       " ('sugar', 0.8009897470474243)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.most_similar(\"coke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5197e032-0692-4f82-8d97-e63b71cce4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contextually Close Words: ('tea','coffee') = 0.107\n",
      "Syntactically Close Words:   ('tea','pea') = 0.525\n",
      "More Examples:           ('black','coffee') = 0.425\n",
      "More Examples:           ('white','orange') = 0.173\n"
     ]
    }
   ],
   "source": [
    "print(f\"Contextually Close Words: ('tea','coffee') = {round(glove.distance('tea','coffee'),3)}\")\n",
    "print(f\"Syntactically Close Words:   ('tea','pea') = {round(glove.distance('tea','pea'),3)}\")\n",
    "print(f\"More Examples:           ('black','coffee') = {round(glove.distance('black','coffee'),3)}\")\n",
    "print(f\"More Examples:           ('white','orange') = {round(glove.distance('white','orange'),3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d331b90-4816-4aa3-a76a-cac2b8eb9aef",
   "metadata": {},
   "source": [
    "<a id=\"ftext\"></a>\n",
    "___\n",
    "# FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a245f922-9c87-4e40-b241-fdec5afebad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext = api.load(\"fasttext-wiki-news-subwords-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eb0100-79bc-443c-b07b-f0cbe3bc014c",
   "metadata": {},
   "source": [
    "<a id=\"elmo\"></a>\n",
    "___\n",
    "# ELMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "855a478b-f174-4b73-9bbc-9acab3d8fea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Exporting/importing meta graphs is not supported when eager execution is enabled. No graph exists when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_hub\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhub\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m elmo \u001b[38;5;241m=\u001b[39m \u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://tfhub.dev/google/elmo/2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\adp_llm\\Lib\\site-packages\\tensorflow_hub\\module.py:176\u001b[0m, in \u001b[0;36mModule.__init__\u001b[1;34m(self, spec, trainable, name, tags)\u001b[0m\n\u001b[0;32m    172\u001b[0m   abs_parent_scope \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(abs_parent_scope):\n\u001b[0;32m    175\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tags\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\adp_llm\\Lib\\site-packages\\tensorflow_hub\\native_module.py:387\u001b[0m, in \u001b[0;36m_ModuleSpec._create_impl\u001b[1;34m(self, name, trainable, tags)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, trainable, tags):\n\u001b[0;32m    386\u001b[0m   meta_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_saved_model_handler\u001b[38;5;241m.\u001b[39mget_meta_graph(tags\u001b[38;5;241m=\u001b[39mtags)\n\u001b[1;32m--> 387\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ModuleImpl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m      \u001b[49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmeta_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkpoint_variables_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\adp_llm\\Lib\\site-packages\\tensorflow_hub\\native_module.py:451\u001b[0m, in \u001b[0;36m_ModuleImpl.__init__\u001b[1;34m(self, spec, meta_graph, trainable, checkpoint_path, name)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# Clear dependencies so modules can be constructed from deep inside\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# functions that have dependencies active. Note that the dependencies\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# would be active when applying the Module signature, just not active\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;66;03m# when creating the Module state. This use case has showed up in some\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;66;03m# TPU training code.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m scope_func():\n\u001b[1;32m--> 451\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\adp_llm\\Lib\\site-packages\\tensorflow_hub\\native_module.py:454\u001b[0m, in \u001b[0;36m_ModuleImpl._init_state\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[1;32m--> 454\u001b[0m   variable_tensor_map, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_state_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_map \u001b[38;5;241m=\u001b[39m recover_partitioned_variable_map(\n\u001b[0;32m    456\u001b[0m       get_node_map_from_tensor_map(variable_tensor_map))\n\u001b[0;32m    457\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_map \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_path:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\adp_llm\\Lib\\site-packages\\tensorflow_hub\\native_module.py:509\u001b[0m, in \u001b[0;36m_ModuleImpl._create_state_graph\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    505\u001b[0m meta_graph_lib\u001b[38;5;241m.\u001b[39mfilter_collections(meta_graph, import_collections)\n\u001b[0;32m    506\u001b[0m meta_graph_lib\u001b[38;5;241m.\u001b[39mprefix_shared_name_attributes(meta_graph,\n\u001b[0;32m    507\u001b[0m                                              absolute_scope_name)\n\u001b[1;32m--> 509\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_meta_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimport_scope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_scope_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;66;03m# Build a list from the variable name in the module definition to the actual\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;66;03m# instantiated variables.\u001b[39;00m\n\u001b[0;32m    516\u001b[0m variables_tensor_map \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\adp_llm\\Lib\\site-packages\\tensorflow\\python\\training\\saver.py:1583\u001b[0m, in \u001b[0;36mimport_meta_graph\u001b[1;34m(meta_graph_or_file, clear_devices, import_scope, **kwargs)\u001b[0m\n\u001b[0;32m   1473\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain.import_meta_graph\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   1474\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimport_meta_graph\u001b[39m(meta_graph_or_file,\n\u001b[0;32m   1475\u001b[0m                       clear_devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1476\u001b[0m                       import_scope\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1477\u001b[0m                       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Recreates a Graph saved in a `MetaGraphDef` proto.\u001b[39;00m\n\u001b[0;32m   1479\u001b[0m \n\u001b[0;32m   1480\u001b[0m \u001b[38;5;124;03m  This function takes a `MetaGraphDef` protocol buffer as input. If\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1581\u001b[0m \u001b[38;5;124;03m  @end_compatibility\u001b[39;00m\n\u001b[0;32m   1582\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=g-doc-exception\u001b[39;00m\n\u001b[1;32m-> 1583\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_import_meta_graph_with_return_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeta_graph_or_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1584\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mclear_devices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimport_scope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1585\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\adp_llm\\Lib\\site-packages\\tensorflow\\python\\training\\saver.py:1595\u001b[0m, in \u001b[0;36m_import_meta_graph_with_return_elements\u001b[1;34m(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs)\u001b[0m\n\u001b[0;32m   1593\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Import MetaGraph, and return both a saver and returned elements.\"\"\"\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m-> 1595\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExporting/importing meta graphs is not supported when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1596\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager execution is enabled. No graph exists when eager \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1597\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(meta_graph_or_file, meta_graph_pb2\u001b[38;5;241m.\u001b[39mMetaGraphDef):\n\u001b[0;32m   1599\u001b[0m   meta_graph_def \u001b[38;5;241m=\u001b[39m meta_graph\u001b[38;5;241m.\u001b[39mread_meta_graph_file(meta_graph_or_file)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Exporting/importing meta graphs is not supported when eager execution is enabled. No graph exists when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa3bdf4-8329-41a9-bf72-cdbc1c29a1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a random sentence\n",
    "x = [\"Roasted ants are a popular snack in Columbia\"]\n",
    "\n",
    "# Extract ELMo features \n",
    "embeddings = elmo(x, signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
